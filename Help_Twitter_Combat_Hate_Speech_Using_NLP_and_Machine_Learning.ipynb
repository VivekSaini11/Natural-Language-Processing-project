{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Help Twitter Combat Hate Speech Using NLP and Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCU48ys7emAzFKDT4D77sn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VivekSaini11/Natural-Language-Processing-project/blob/master/Help_Twitter_Combat_Hate_Speech_Using_NLP_and_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WG7-kXscLq4",
        "colab_type": "text"
      },
      "source": [
        "**DESCRIPTION**\n",
        "\n",
        "Using NLP and ML, make a model to identify hate speech (racist or sexist tweets) in Twitter.\n",
        "\n",
        "**Problem Statement**:  \n",
        "\n",
        "Twitter is the biggest platform where anybody and everybody can have their views heard. Some of these voices spread hate and negativity. Twitter is wary of its platform being used as a medium  to spread hate. \n",
        "\n",
        "You are a data scientist at Twitter, and you will help Twitter in identifying the tweets with hate speech and removing them from the platform. You will use NLP techniques, perform specific cleanup for tweets data, and make a robust model.\n",
        "\n",
        "**Domain: Social Media**\n",
        "\n",
        "Analysis to be done: Clean up tweets and build a classification model by using NLP techniques, cleanup specific for tweets data, regularization and hyperparameter tuning using stratified k-fold and cross validation to get the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFORY1_Ab7k6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "68fec174-f0a3-4c56-eba6-1747de26eb49"
      },
      "source": [
        "import pandas as pd\t\n",
        "from collections import Counter \n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT7_2B9NYveP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "1752e7c5-152b-4bcd-cf58-608d6fa81dfa"
      },
      "source": [
        "# Load the tweets file using read_csv function from Pandas package. \n",
        "data = pd.read_csv('TwitterHate.csv')\n",
        "data"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>31958</td>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>31959</td>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>31960</td>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>31961</td>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>31962</td>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  label                                              tweet\n",
              "0          1      0   @user when a father is dysfunctional and is s...\n",
              "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2          3      0                                bihday your majesty\n",
              "3          4      0  #model   i love u take with u all the time in ...\n",
              "4          5      0             factsguide: society now    #motivation\n",
              "...      ...    ...                                                ...\n",
              "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
              "31958  31959      0    to see nina turner on the airwaves trying to...\n",
              "31959  31960      0  listening to sad songs on a monday morning otw...\n",
              "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
              "31961  31962      0                   thank you @user for you follow  \n",
              "\n",
              "[31962 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgNwcozFZLOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b1ce97c-1c1b-4841-d628-566e76c955ca"
      },
      "source": [
        "# Get the tweets into a list for easy text cleanup and manipulation.\n",
        "tweet = data['tweet'].tolist()\n",
        "tweet[:1]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsyQIM7AZmJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "71bddcc0-c2a4-4ce0-be55-228263bfe521"
      },
      "source": [
        "# Normalize the casing.  \n",
        "tokenized_sents = [word_tokenize(i) for i in tweet]\n",
        "for word in tokenized_sents[0]:\n",
        "   print(word.lower())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@\n",
            "user\n",
            "when\n",
            "a\n",
            "father\n",
            "is\n",
            "dysfunctional\n",
            "and\n",
            "is\n",
            "so\n",
            "selfish\n",
            "he\n",
            "drags\n",
            "his\n",
            "kids\n",
            "into\n",
            "his\n",
            "dysfunction\n",
            ".\n",
            "#\n",
            "run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkO7oyb8bADM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "3889d82a-4c06-4594-84f8-7a63901d4143"
      },
      "source": [
        "# Using regular expressions, remove user handles. These begin with '@’.\n",
        "tokenized_sents = [word_tokenize(i) for i in tweet]\n",
        "for word in tokenized_sents[0]:\n",
        "    if word.startswith('@') is False:\n",
        "      print(' '.join([word]));"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "user\n",
            "when\n",
            "a\n",
            "father\n",
            "is\n",
            "dysfunctional\n",
            "and\n",
            "is\n",
            "so\n",
            "selfish\n",
            "he\n",
            "drags\n",
            "his\n",
            "kids\n",
            "into\n",
            "his\n",
            "dysfunction\n",
            ".\n",
            "#\n",
            "run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne3FJ6-CfYsb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d45fdb1e-18b8-4e9d-d9c2-18e1ec35d195"
      },
      "source": [
        "# Using regular expressions, remove URLs.\n",
        "tokenized_sents = [word_tokenize(i) for i in tweet]\n",
        "for word in tokenized_sents[0]:\n",
        "  if word.startswith('@') is False:\n",
        "    print(re.sub(r\"http\\S+\", \"\", word));"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "user\n",
            "when\n",
            "a\n",
            "father\n",
            "is\n",
            "dysfunctional\n",
            "and\n",
            "is\n",
            "so\n",
            "selfish\n",
            "he\n",
            "drags\n",
            "his\n",
            "kids\n",
            "into\n",
            "his\n",
            "dysfunction\n",
            ".\n",
            "#\n",
            "run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk5nKGbmxQ-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "f1dec7fd-a26b-434d-dfda-45e1d683a345"
      },
      "source": [
        "# Using TweetTokenizer from NLTK, tokenize the tweets into individual terms.\n",
        "from nltk.tokenize import TweetTokenizer \n",
        "tk = TweetTokenizer() \n",
        "geek = tk.tokenize(data['tweet'].tolist()[0])  \n",
        "geek"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@user',\n",
              " 'when',\n",
              " 'a',\n",
              " 'father',\n",
              " 'is',\n",
              " 'dysfunctional',\n",
              " 'and',\n",
              " 'is',\n",
              " 'so',\n",
              " 'selfish',\n",
              " 'he',\n",
              " 'drags',\n",
              " 'his',\n",
              " 'kids',\n",
              " 'into',\n",
              " 'his',\n",
              " 'dysfunction',\n",
              " '.',\n",
              " '#run']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g7t0yPlxxB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6ad25f63-05c0-4cf7-f166-7c7b4218f4b5"
      },
      "source": [
        "# Remove stop words.\n",
        "tokens_without = [word for word in tokenized_sents[0] if not word in stopwords.words()]\n",
        "tokens_without"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@',\n",
              " 'user',\n",
              " 'father',\n",
              " 'dysfunctional',\n",
              " 'selfish',\n",
              " 'drags',\n",
              " 'kids',\n",
              " 'dysfunction',\n",
              " '.',\n",
              " '#',\n",
              " 'run']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceebIMCLx-12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "0ad2e0d8-eea6-400f-ecbb-38347cf1a534"
      },
      "source": [
        "# Remove redundant terms like ‘amp’, ‘rt’, etc.\n",
        "tokenized_sents = [word_tokenize(i) for i in tweet]\n",
        "for word in tokenized_sents[0]:\n",
        "  if word.startswith('amp') is False | word.startswith('rt') is False:\n",
        "    print(' '.join([word]));"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@\n",
            "user\n",
            "when\n",
            "a\n",
            "father\n",
            "is\n",
            "dysfunctional\n",
            "and\n",
            "is\n",
            "so\n",
            "selfish\n",
            "he\n",
            "drags\n",
            "his\n",
            "kids\n",
            "into\n",
            "his\n",
            "dysfunction\n",
            ".\n",
            "#\n",
            "run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcE1XqC30Kak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "970279a6-d2b8-432f-d9c9-3abcd70dd680"
      },
      "source": [
        "# Remove ‘#’ symbols from the tweet while retaining the term.\n",
        "tokenized_sents = [word_tokenize(i) for i in tweet]\n",
        "for word in tokenized_sents[0]:\n",
        "  if word.startswith('@') is False:\n",
        "    print(word.replace(\"#\",\" \"));"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "user\n",
            "when\n",
            "a\n",
            "father\n",
            "is\n",
            "dysfunctional\n",
            "and\n",
            "is\n",
            "so\n",
            "selfish\n",
            "he\n",
            "drags\n",
            "his\n",
            "kids\n",
            "into\n",
            "his\n",
            "dysfunction\n",
            ".\n",
            " \n",
            "run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSqDhVCp0bVH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1db5ab5d-03e2-4e85-b8dd-bfae5754d38a"
      },
      "source": [
        "# Extra cleanup by removing terms with a length of 1.\n",
        "tokenized_sents = [word_tokenize(i) for i in tweet]\n",
        "for word in tokenized_sents[0]:\n",
        "    if word.count != 0:\n",
        "      print(' '.join([word]));"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@\n",
            "user\n",
            "when\n",
            "a\n",
            "father\n",
            "is\n",
            "dysfunctional\n",
            "and\n",
            "is\n",
            "so\n",
            "selfish\n",
            "he\n",
            "drags\n",
            "his\n",
            "kids\n",
            "into\n",
            "his\n",
            "dysfunction\n",
            ".\n",
            "#\n",
            "run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWbrCxe50whX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "14af1c12-1d6b-4e99-cf1c-8d108e47c30b"
      },
      "source": [
        "# First, get all the tokenized terms into one large list\n",
        "tokenized_sents = [word_tokenize(i) for i in tweet]\n",
        "tokenized_sents[0]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@',\n",
              " 'user',\n",
              " 'when',\n",
              " 'a',\n",
              " 'father',\n",
              " 'is',\n",
              " 'dysfunctional',\n",
              " 'and',\n",
              " 'is',\n",
              " 'so',\n",
              " 'selfish',\n",
              " 'he',\n",
              " 'drags',\n",
              " 'his',\n",
              " 'kids',\n",
              " 'into',\n",
              " 'his',\n",
              " 'dysfunction',\n",
              " '.',\n",
              " '#',\n",
              " 'run']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTq9xKea38S0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d577e1b-87b7-46c1-ec43-b3e9865a32d7"
      },
      "source": [
        "# Use the counter and find the 10 most common terms.\n",
        "tokenized_sents = [word_tokenize(i) for i in tweet]\n",
        "for word in tokenized_sents:\n",
        "  word_count  = Counter(word) \n",
        "  most_occur = word_count .most_common(10)  \n",
        "  most_occur\n",
        "most_occur  "
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('you', 2), ('thank', 1), ('@', 1), ('user', 1), ('for', 1), ('follow', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXSwczK6qQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform train_test_split using sklearn.\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[\"tweet\"], data[\"label\"], test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9nLEq227iox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "adc635a7-f128-4a30-f4b0-5b44cc7e06a3"
      },
      "source": [
        "# Instantiate with a maximum of 5000 terms in your vocabulary.\n",
        "tfidf = TfidfVectorizer(analyzer='char',ngram_range=(2,3),token_pattern=r'\\w{1,}',max_features=5000)\n",
        "train_tfidf = tfidf.fit_transform(X_train)\n",
        "test_tfidf = tfidf.transform(X_train)\n",
        "test_tfidf = tfidf.transform(X_test)\n",
        "test_tfidf"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<6393x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 813994 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDAJeyjrEqEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43d3aa87-d54a-44d9-f9d8-2c4228f4dad4"
      },
      "source": [
        "# Model building: Ordinary Logistic Regression\n",
        "clf = LogisticRegression(C=1.0)\n",
        "clf.fit(train_tfidf, y_train)\n",
        "pred = clf.predict(test_tfidf)\n",
        "pred"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8SNQ6tNGJO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5961b791-77c2-4ecd-9713-5813caedfcb0"
      },
      "source": [
        "# Model evaluation: Accuracy, recall, and f_1 score.\n",
        "scores = cross_val_score(clf, train_tfidf, y_train, cv=5, scoring=\"f1\")\n",
        "scores"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.52427184, 0.53510436, 0.52895753, 0.52071006, 0.54166667])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeuP6KDfGwvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "84525c27-8eff-49e1-d4c8-ef956be5901e"
      },
      "source": [
        "# Import GridSearch and StratifiedKFold because of class imbalance.\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "for train_ix, test_ix in kfold.split(data[\"tweet\"],data[\"label\"]):\n",
        "\ttrain_X, test_X = data[\"tweet\"][train_ix], data[\"tweet\"][test_ix]\n",
        "\ttrain_y, test_y = data[\"label\"][train_ix], data[\"label\"][test_ix]\n",
        "\ttrain_0, train_1 = len(train_y[train_y==0]), len(train_y[train_y==1])\n",
        "\ttest_0, test_1 = len(test_y[test_y==0]), len(test_y[test_y==1])\n",
        "\tprint('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Train: 0=23776, 1=1793, Test: 0=5944, 1=449\n",
            ">Train: 0=23776, 1=1793, Test: 0=5944, 1=449\n",
            ">Train: 0=23776, 1=1794, Test: 0=5944, 1=448\n",
            ">Train: 0=23776, 1=1794, Test: 0=5944, 1=448\n",
            ">Train: 0=23776, 1=1794, Test: 0=5944, 1=448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ydGxsS1Ioiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15f89b7d-21e6-4548-fa1b-7b0ba6cf7a25"
      },
      "source": [
        "# split into train/test sets with same class ratio\n",
        "trainX, testX, trainy, testy = train_test_split(data[\"tweet\"], data[\"label\"], test_size = 0.2, random_state = 0)\n",
        "train_0, train_1 = len(trainy[trainy==0]), len(trainy[trainy==1])\n",
        "test_0, test_1 = len(testy[testy==0]), len(testy[testy==1])\n",
        "print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Train: 0=23735, 1=1834, Test: 0=5985, 1=408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE0KryO8JlPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1bbd4c9e-bd9a-4e21-bc6b-fb5665153282"
      },
      "source": [
        "# Regularization and Hyperparameter tuning\n",
        "balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
        "param_grid = dict(class_weight=balance)\n",
        "grid = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, cv=kfold, scoring='roc_auc')\n",
        "grid_result = grid.fit(train_tfidf, y_train)\n",
        "# report the best configuration\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "# report all configurations\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.956948 using {'class_weight': {0: 1, 1: 10}}\n",
            "0.945012 (0.005574) with: {'class_weight': {0: 100, 1: 1}}\n",
            "0.947798 (0.005304) with: {'class_weight': {0: 10, 1: 1}}\n",
            "0.948890 (0.005000) with: {'class_weight': {0: 1, 1: 1}}\n",
            "0.956948 (0.003562) with: {'class_weight': {0: 1, 1: 10}}\n",
            "0.956823 (0.003340) with: {'class_weight': {0: 1, 1: 100}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDLb_oFYNkrs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c67346ed-956b-4644-ed94-4506ae8b942d"
      },
      "source": [
        "# What are the best parameters?\n",
        "grid_result.best_estimator_"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight={0: 1, 1: 10}, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPJ9uFvoNYj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7148049d-5898-40fa-c54e-577ffeda53be"
      },
      "source": [
        "# Predict and evaluate using the best estimator.\n",
        "prediction = grid_result.best_estimator_.predict(test_tfidf)\n",
        "prediction"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u4TjcXCPSr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtpySd8BNzWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ff64f85-deb7-4ee6-ea54-4ed9c1c9f419"
      },
      "source": [
        "# What is the recall on the test set for the toxic comments?\n",
        "scores = cross_val_score(grid_result.best_estimator_, train_tfidf, y_train, cv=5, scoring=\"f1\")\n",
        "scores"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.63522013, 0.65274725, 0.63921993, 0.62582057, 0.61636557])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcOLmrP7OTW_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11a565e4-617b-417e-99a0-822d98190485"
      },
      "source": [
        "# What is the f_1 score?\n",
        "score = f1_score(y_test, prediction, average='binary')\n",
        "print('F-Measure: %.3f' % score)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-Measure: 0.623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpkEV06KPYUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2c38c77-964f-4845-ca19-0e5b00953f3d"
      },
      "source": [
        "# Choose ‘recall’ as the metric for scoring.\n",
        "print(metrics.f1_score(y_test, prediction))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6227106227106227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kknVOUuIP14V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "528888cb-4780-413a-f4dd-c8ec55d1dc17"
      },
      "source": [
        "# Evaluate the predictions on the train set: accuracy, recall, and f_1 score.\n",
        "accuracy = metrics.accuracy_score(y_test, prediction)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "precision = metrics.precision_score(y_test, prediction)\n",
        "print('Precision: %f' % precision)\n",
        "recall = metrics.recall_score(y_test, prediction)\n",
        "print('Recall: %f' % recall)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.935555\n",
            "Precision: 0.497076\n",
            "Recall: 0.833333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}